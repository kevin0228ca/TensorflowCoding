{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "source": [
    "# Get data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'\n",
    "csv_file = 'datasets/petfinder-mini/petfinder-mini.csv'\n",
    "\n",
    "tf.keras.utils.get_file('petfinder_mini.zip', dataset_url, extract=True, cache_dir='.')\n",
    "dataframe = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Type  Age                Breed1  Gender Color1    Color2 MaturitySize  \\\n",
       "0  Cat    3                 Tabby    Male  Black     White        Small   \n",
       "1  Cat    1  Domestic Medium Hair    Male  Black     Brown       Medium   \n",
       "2  Dog    1           Mixed Breed    Male  Brown     White       Medium   \n",
       "3  Dog    4           Mixed Breed  Female  Black     Brown       Medium   \n",
       "4  Dog    1           Mixed Breed    Male  Black  No Color       Medium   \n",
       "\n",
       "  FurLength Vaccinated Sterilized   Health  Fee  \\\n",
       "0     Short         No         No  Healthy  100   \n",
       "1    Medium   Not Sure   Not Sure  Healthy    0   \n",
       "2    Medium        Yes         No  Healthy    0   \n",
       "3     Short        Yes         No  Healthy  150   \n",
       "4     Short         No         No  Healthy    0   \n",
       "\n",
       "                                         Description  PhotoAmt  AdoptionSpeed  \n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...         1              2  \n",
       "1  I just found it alone yesterday near my apartm...         2              0  \n",
       "2  Their pregnant mother was dumped by her irresp...         7              3  \n",
       "3  Good guard dog, very alert, active, obedience ...         8              2  \n",
       "4  This handsome yet cute boy is up for adoption....         3              2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Age</th>\n      <th>Breed1</th>\n      <th>Gender</th>\n      <th>Color1</th>\n      <th>Color2</th>\n      <th>MaturitySize</th>\n      <th>FurLength</th>\n      <th>Vaccinated</th>\n      <th>Sterilized</th>\n      <th>Health</th>\n      <th>Fee</th>\n      <th>Description</th>\n      <th>PhotoAmt</th>\n      <th>AdoptionSpeed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cat</td>\n      <td>3</td>\n      <td>Tabby</td>\n      <td>Male</td>\n      <td>Black</td>\n      <td>White</td>\n      <td>Small</td>\n      <td>Short</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Healthy</td>\n      <td>100</td>\n      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Cat</td>\n      <td>1</td>\n      <td>Domestic Medium Hair</td>\n      <td>Male</td>\n      <td>Black</td>\n      <td>Brown</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Not Sure</td>\n      <td>Not Sure</td>\n      <td>Healthy</td>\n      <td>0</td>\n      <td>I just found it alone yesterday near my apartm...</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dog</td>\n      <td>1</td>\n      <td>Mixed Breed</td>\n      <td>Male</td>\n      <td>Brown</td>\n      <td>White</td>\n      <td>Medium</td>\n      <td>Medium</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Healthy</td>\n      <td>0</td>\n      <td>Their pregnant mother was dumped by her irresp...</td>\n      <td>7</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Dog</td>\n      <td>4</td>\n      <td>Mixed Breed</td>\n      <td>Female</td>\n      <td>Black</td>\n      <td>Brown</td>\n      <td>Medium</td>\n      <td>Short</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Healthy</td>\n      <td>150</td>\n      <td>Good guard dog, very alert, active, obedience ...</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dog</td>\n      <td>1</td>\n      <td>Mixed Breed</td>\n      <td>Male</td>\n      <td>Black</td>\n      <td>No Color</td>\n      <td>Medium</td>\n      <td>Short</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Healthy</td>\n      <td>0</td>\n      <td>This handsome yet cute boy is up for adoption....</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# check data\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplify the target for binary classfication\n",
    "dataframe['target'] = np.where(dataframe['AdoptionSpeed'] == 4, 0, 1)  # original dataset 4 is not adopted\n",
    "# remove unused columns\n",
    "dataframe = dataframe.drop(columns=['AdoptionSpeed', 'Description'])"
   ]
  },
  {
   "source": [
    "# Preprocess data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7383 train examples\n1846 val examples\n2308 test examples\n"
     ]
    }
   ],
   "source": [
    "# split sets\n",
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'val examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset from dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "\n",
    "    labels = dataframe.pop('target')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Every feature: ['Type', 'Age', 'Breed1', 'Gender', 'Color1', 'Color2', 'MaturitySize', 'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Fee', 'PhotoAmt']\nA batch of ages: tf.Tensor([ 2 24 12  8  2], shape=(5,), dtype=int64)\nA batch of labels: tf.Tensor([0 1 0 1 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# check dataset\n",
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()))\n",
    "print('A batch of ages:', train_features['Age'])\n",
    "print('A batch of labels:', label_batch)"
   ]
  },
  {
   "source": [
    "### preprocessing layers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize numeric features\n",
    "def get_normalization_layer(name, dataset):\n",
    "    normalizer = preprocessing.Normalization()\n",
    "\n",
    "    # create a dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    normalizer.adapt(feature_ds)\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[-0.51509947],\n",
       "       [-0.84064126],\n",
       "       [-0.84064126],\n",
       "       [-0.84064126],\n",
       "       [ 1.1126094 ]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "photo_count_col = train_features['PhotoAmt']\n",
    "layer = get_normalization_layer('PhotoAmt', train_ds)\n",
    "layer(photo_count_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode categorical features\n",
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    # StringLookup layer which turns strings to integer indices\n",
    "    if dtype == 'string':\n",
    "        index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = preprocessing.IntegerLookup(max_values=max_tokens)\n",
    "\n",
    "    # create a dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # learn the set of possible values and assign them a fixed integer index\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # create Discretization for integer indices\n",
    "    encoder = preprocessing.CategoryEncoding(max_tokens=index.vocab_size())\n",
    "\n",
    "    # create a dataset that only yields our feature\n",
    "    feature_ds = feature_ds.map(index)\n",
    "\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # one hot encode\n",
    "    return lambda feature: encoder(index(feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# encode the type feature\n",
    "type_col = train_features['Type']\n",
    "layer = get_category_encoding_layer('Type', train_ds, 'string')\n",
    "layer(type_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
       "array([[0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]], dtype=float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# can also encode integer features\n",
    "type_col = train_features['Age']\n",
    "category_encoding_layer = get_category_encoding_layer('Age', train_ds, 'int64', 5)\n",
    "category_encoding_layer(type_col)"
   ]
  },
  {
   "source": [
    "# Choose features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# numeric features\n",
    "for header in ['PhotoAmt', 'Fee']:\n",
    "    numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds)\n",
    "    encoded_numeric_col = normalization_layer(numeric_col)\n",
    "    all_inputs.append(numeric_col)\n",
    "    encoded_features.append(encoded_numeric_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features of integers\n",
    "age_col = tf.keras.Input(shape=(1,), name='Age', dtype='int64')\n",
    "encoding_layer = get_category_encoding_layer('Age', train_ds, dtype='int64', max_tokens=5)\n",
    "encoded_age_col = encoding_layer(age_col)\n",
    "all_inputs.append(age_col)\n",
    "encoded_features.append(encoded_age_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features of strings\n",
    "categorical_cols = ['Type', 'Color1', 'Color2', 'Gender', 'MaturitySize',\n",
    "                    'FurLength', 'Vaccinated', 'Sterilized', 'Health', 'Breed1']\n",
    "\n",
    "for header in categorical_cols:\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "    encoding_layer = get_category_encoding_layer(header, train_ds, dtype='string', max_tokens=5)\n",
    "    encoded_categorical_col = encoding_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "source": [
    "# Build model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# show connectivity\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 1s 18ms/step - loss: 0.6064 - accuracy: 0.6366 - val_loss: 0.5621 - val_accuracy: 0.7232\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5833 - accuracy: 0.6721 - val_loss: 0.5449 - val_accuracy: 0.7216\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5597 - accuracy: 0.6908 - val_loss: 0.5355 - val_accuracy: 0.7221\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5535 - accuracy: 0.7004 - val_loss: 0.5277 - val_accuracy: 0.7221\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.6984 - val_loss: 0.5224 - val_accuracy: 0.7302\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 0s 7ms/step - loss: 0.5386 - accuracy: 0.7123 - val_loss: 0.5182 - val_accuracy: 0.7329\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7154 - val_loss: 0.5157 - val_accuracy: 0.7313\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5322 - accuracy: 0.7154 - val_loss: 0.5129 - val_accuracy: 0.7324\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7176 - val_loss: 0.5111 - val_accuracy: 0.7313\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 0s 6ms/step - loss: 0.5234 - accuracy: 0.7200 - val_loss: 0.5089 - val_accuracy: 0.7313\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11a41143c10>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7305\n",
      "Accuracy 0.7305026054382324\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "source": [
    "# Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: my_pet_classifier\\assets\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x0000011AF41AC430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x0000011AF41B7F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x0000011AF41D8160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x0000011AF41B7820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x0000011AF419E820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x0000011AF41D8700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x0000011AF419E160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model.save('my_pet_classifier')\n",
    "reloaded_model = tf.keras.models.load_model('my_pet_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This particular pet had a 84.6 percent probability of getting adopted.\n"
     ]
    }
   ],
   "source": [
    "sample = {\n",
    "    'Type': 'Cat',\n",
    "    'Age': 3,\n",
    "    'Breed1': 'Tabby',\n",
    "    'Gender': 'Male',\n",
    "    'Color1': 'Black',\n",
    "    'Color2': 'White',\n",
    "    'MaturitySize': 'Small',\n",
    "    'FurLength': 'Short',\n",
    "    'Vaccinated': 'No',\n",
    "    'Sterilized': 'No',\n",
    "    'Health': 'Healthy',\n",
    "    'Fee': 100,\n",
    "    'PhotoAmt': 2,\n",
    "}\n",
    "\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "predictions = reloaded_model.predict(input_dict)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This particular pet had a %.1f percent probability \"\n",
    "    \"of getting adopted.\" % (100 * prob)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}